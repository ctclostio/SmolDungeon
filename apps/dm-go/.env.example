# Server Configuration
PORT=3000
DB_PATH=./dm-server.db

# LLM Configuration (OpenAI compatible)
LLM_API_KEY=your-openai-api-key-here
LLM_BASE_URL=
LLM_MODEL=gpt-3.5-turbo
LLM_MAX_TOKENS=150
LLM_TEMPERATURE=0.7

# Local Model Configuration (for gpt-oss-20b and similar)
LLM_LOCAL_ENABLED=false
LLM_LOCAL_BASE_URL=http://localhost:8000/v1
LLM_LOCAL_MODEL=gpt-oss-20b
LLM_LOCAL_MAX_TOKENS=200
LLM_LOCAL_TEMPERATURE=0.8

# Model Selection: "remote", "local", or "auto" (tries local first, falls back to remote)
LLM_PREFERRED_MODEL=auto